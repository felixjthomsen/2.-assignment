---
title: "BA-BINTV2006U  Programming and Data Analysis for Business: Exercise 2"
author: "by Felix Thomsen, Alexander Schiøtz, Anders Laurents, Bertram Hage"
date: "2024-11-01"
output: 
  html_document:
    theme: sandstone
    code_folding: show
---

## 1. packages + dataload
<!-- 2. Load the dataset into R and inspect its structure. How many rows, how many columns, what is the
summary statistics for the numeric variables? -->
```{r init, warning = FALSE, message=FALSE}
library(knitr)
library(markdown)
library(rmarkdown)
library(tidyverse)
library(lubridate)
library(readxl)
theme_set(theme_bw())
```
```{r, message=FALSE}
data <- read_csv("data.csv")
```

## Create a point plot or jitter plot
```{r}
#Jitter plot for hours studied and exam score
ggplot(data, aes(x = Hours_Studied, y = Exam_Score, color = Gender)) + geom_jitter() + scale_fill_manual(values = c("blue", "pink")) + labs(title = "Jitter plots of hours studied and exam scores + colored by Gender")
```

## Create a boxplot or a bar plot. 
To visualize the distribution of "Hours_Studied" by "Gender" we selected a boxplot:ß
```{r}
# data$Hours_Studied

ggplot(data, aes(x = data$Gender, y = data$Hours_Studied)) + geom_boxplot() +   labs(title = "Boxplot of Hours Studied by Gender", x = "Gender", y = "Hours Studied")
```

Generally we see that males and females studies the same amount of hours.

## Generate a histogram to visualize the distribution of one of the numerical variables.
```{r}

ggplot(data, aes(x = Exam_Score)) + geom_histogram(binwidth = 1, aes(fill = ..count..)) + scale_fill_gradient(low = "green", high = "blue") + labs(title = "Histogram of Exam Scores by Student", x = "Exam Score" , y = "Counts of Students")

```

## Create a visualization of own choice that you have “polished”,  and write what the purpose is with  your visualization. (Is it for a managerial decision? A publication? How?)
The plot below shows the number of students sorted by Parental involvement. This could be useful for a school to see how many students have a high parental involvement and how many have a low parental involvement. This could be further analysed to see if there is a correlation between parental involvement and student performance. First of all the plot greatly visualizes if there is a noticeable difference in the number of students with high and low parental involvement. Most students have a medium parental involvement, follow by high involvement and lastly low involvement. It would be interesting to see if there is a correlation between parental involvement and student performance. This plot can serve as an inspiration to further investigate the visual difference seen in the plot.
```{r}
ggplot(data, aes(x=Parental_Involvement, fill = Parental_Involvement))+
  geom_bar() +
  labs(title="Number of students sorted by Parental involvement", x="Parental involvement", y="Students")+
  ylim(0,4000) +
  theme(legend.position = "none",axis.text = element_text(size = 12))
```

## Create a linear model in which you model using at least tree input/independant variables. 
We consider the numeric variables "Hours_Studied", "Attendance", "Tutoring_Sessions", "Previous_Scores", "Physical_Activity" and "Sleep_Hours" as input variables.
We use the "Exam_Score" as the dependent variable.
Of the variables considered 4 are thought to directly impact the students performance, while sleep hours and physical activity are thought to be less important.

We create two linear models and compare them using an ANOVA test.
```{r}
lm1 <- lm(Exam_Score ~ Hours_Studied + Attendance + Tutoring_Sessions + Previous_Scores, data = data)
lm2 <- lm(Exam_Score ~ Hours_Studied + Attendance + Sleep_Hours+ Previous_Scores + Tutoring_Sessions + Physical_Activity, data = data)
```

```{r}
anova(lm1,lm2)
```

The two models are not significantly different from each other and thus we favor the simpler model.

We check for normality and homoschedasticity
```{r, echo=F,fig.height = 5, fig.align = 'center'}
par(mfrow=c(2,2))
plot(lm1,2, main="Model 1")
plot(lm2,2, main="Model 2")
plot(lm1,1)
plot(lm2,1)
```

The residuals of both models are normally distributed and homoschedastic.

## Visualize the model output using dotwhiskers and stargazer
```{r, warning=F, message=F, fig.height = 4, fig.align = 'center'}
library(dotwhisker)
dwplot(lm1, dot_args = list(size = 2, color = "black"),
       whisker_args = list(color = "black"),
       vline = geom_vline(xintercept = 0, colour = "grey50", linetype = 2)) +
  ggtitle("Dot-and-Whisker plot for a linear regression model") +
  theme(plot.title = element_text(hjust = 1.0))
```

From the dot-wisker plot we can see that all variables have positive coefficient which is in line with our expectations.
`Tutoring_Sessions` have a larger confidence interval while the other have very small confidence intervals.

We see the whole summary of the two models in the table below.

```{r, warning=FALSE, eval=FALSE}
library(stargazer)
fil <- stargazer(lm1, lm2,title="Results", type = "html", align=TRUE)
write(fil, file = "results.html")
```

<table style="text-align:center"><caption><strong>Results</strong></caption>
<tr><td colspan="3" style="border-bottom: 1px solid black"></td></tr><tr><td style="text-align:left"></td><td colspan="2"><em>Dependent variable:</em></td></tr>
<tr><td></td><td colspan="2" style="border-bottom: 1px solid black"></td></tr>
<tr><td style="text-align:left"></td><td colspan="2">Exam_Score</td></tr>
<tr><td style="text-align:left"></td><td>(1)</td><td>(2)</td></tr>
<tr><td colspan="3" style="border-bottom: 1px solid black"></td></tr><tr><td style="text-align:left">Hours_Studied</td><td>0.291<sup>***</sup></td><td>0.291<sup>***</sup></td></tr>
<tr><td style="text-align:left"></td><td>(0.003)</td><td>(0.003)</td></tr>
<tr><td style="text-align:left"></td><td></td><td></td></tr>
<tr><td style="text-align:left">Attendance</td><td>0.197<sup>***</sup></td><td>0.198<sup>***</sup></td></tr>
<tr><td style="text-align:left"></td><td>(0.002)</td><td>(0.002)</td></tr>
<tr><td style="text-align:left"></td><td></td><td></td></tr>
<tr><td style="text-align:left">Sleep_Hours</td><td></td><td>0.006</td></tr>
<tr><td style="text-align:left"></td><td></td><td>(0.012)</td></tr>
<tr><td style="text-align:left"></td><td></td><td></td></tr>
<tr><td style="text-align:left">Tutoring_Sessions</td><td>0.486<sup>***</sup></td><td>0.490<sup>***</sup></td></tr>
<tr><td style="text-align:left"></td><td>(0.019)</td><td>(0.019)</td></tr>
<tr><td style="text-align:left"></td><td></td><td></td></tr>
<tr><td style="text-align:left">Physical_Activity</td><td></td><td>0.185<sup>***</sup></td></tr>
<tr><td style="text-align:left"></td><td></td><td>(0.018)</td></tr>
<tr><td style="text-align:left"></td><td></td><td></td></tr>
<tr><td style="text-align:left">Previous_Scores</td><td>0.048<sup>***</sup></td><td>0.048<sup>***</sup></td></tr>
<tr><td style="text-align:left"></td><td>(0.001)</td><td>(0.001)</td></tr>
<tr><td style="text-align:left"></td><td></td><td></td></tr>
<tr><td style="text-align:left">Constant</td><td>41.141<sup>***</sup></td><td>40.484<sup>***</sup></td></tr>
<tr><td style="text-align:left"></td><td>(0.178)</td><td>(0.207)</td></tr>
<tr><td style="text-align:left"></td><td></td><td></td></tr>
<tr><td colspan="3" style="border-bottom: 1px solid black"></td></tr><tr><td style="text-align:left">Observations</td><td>6,054</td><td>6,054</td></tr>
<tr><td style="text-align:left">R<sup>2</sup></td><td>0.804</td><td>0.808</td></tr>
<tr><td style="text-align:left">Adjusted R<sup>2</sup></td><td>0.804</td><td>0.807</td></tr>
<tr><td style="text-align:left">Residual Std. Error</td><td>1.428 (df = 6049)</td><td>1.415 (df = 6047)</td></tr>
<tr><td style="text-align:left">F Statistic</td><td>6,210.296<sup>***</sup> (df = 4; 6049)</td><td>4,232.548<sup>***</sup> (df = 6; 6047)</td></tr>
<tr><td colspan="3" style="border-bottom: 1px solid black"></td></tr><tr><td style="text-align:left"><em>Note:</em></td><td colspan="2" style="text-align:right"><sup>*</sup>p<0.1; <sup>**</sup>p<0.05; <sup>***</sup>p<0.01</td></tr>
</table>

The first model achieve an adjusted R-squared of 0.804, while the second model achieve an adjusted R-squared of 0.807.
All variables are significant at the 1% level for the first model.

We can evaluate the elasticities of the four variable to see how much they impact the exam score.

```{r}
coef <- coefficients(lm1)

elasticities <- c()
elasticities <- c(elasticities, coef["Hours_Studied"] * mean(data$Hours_Studied) / mean(data$Exam_Score))
elasticities <- c(elasticities, coef["Attendance"] * mean(data$Attendance) / mean(data$Exam_Score))
elasticities <- c(elasticities, coef["Tutoring_Sessions"] * mean(data$Tutoring_Sessions) / mean(data$Exam_Score))
elasticities <- c(elasticities, coef["Previous_Scores"] * mean(data$Previous_Scores) / mean(data$Exam_Score))

elasticities
```

We see that attendance is the most important variable, while tutoring sessions have the smallest impact on the exam score. 

## Reflect on the model – how could it be improved?
The linear models developed in this assignment provided solid predictive power for Exam_Score, with R-squared values around 0.8. However, there are several opportunities to improve the model:
We saw that adding more variables would not improve the model, so therefore we favored the simpliest model. We could have used a selecting method for variable selecting. Backwards selection/elimination could also be used to choose the most important variables. Adding squared terms or interaction effects between variables could help capture some of the non-linear relationships between the variables. For example the amount of hours studied could have a negative effect on the exam score if the student studies too much. An interaction terms would help reveal how, tutoring and previous_scores influence the exam_scores for the students if the relationships is non-linear.


## Reflect on how you have used Generative AI (if you have).
In programming using generative AI models such as large language models can be helpful in resolving technical issues
as well as clarifying concepts. In this assignment we did not use generative AI models to write code or text directly,
however, we did use GPT-4o as a supportive tool to improve our understanding of the concepts and techniques used in the assignment.